{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdee4de-7620-4cf7-91af-05be1a478fad",
   "metadata": {},
   "source": [
    "## Question2: KNN Classification in sklearn\n",
    "\n",
    "Submited by: Nikhil Dhiman 403557424\n",
    "\n",
    "Write and submit your python codes in “Jupyter Notebook” to perform the following tasks (submit the .ipynb file).  Make sure to provide proper descriptions as MarkDown for each section of your code (each section of the code must have a short meaningful description right before that, describing what this part of the code is supposed to do!)\n",
    "\n",
    "\n",
    "A. \r\n",
    "Read the iris flower dataset from the following URL: https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csvLinks to an external site. and assign it to a Pandas DataFrame as you learned in tutorial Lab2-3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bf75149d-a9d4-45bf-8dcf-f76bf21c91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries**\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7f4dd85b-8d0f-4d14-9458-be37250f4261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will read the iris dataset from a URL into a Pandas DataFrame and explore the first few rows to understand the structure of the data.\n",
    "url = \"https://raw.githubusercontent.com/mpourhoma/CS4661/master/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f94de7-6e0b-4ba6-b47d-fbeb6e8c126f",
   "metadata": {},
   "source": [
    "B. Split the dataset into testing and training sets with the following parameters: test_size=0.4, random_state=10\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ab8c7db6-32ff-46e0-9847-1ddc1a8d1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "X = df.drop(\"species\", axis=1)  # All features except 'species'\n",
    "y = df[\"species\"]               # The target variable (species)\n",
    "\n",
    "# Split the dataset (60% training, 40% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89648626-28f2-4896-af2b-d202a28232bb",
   "metadata": {},
   "source": [
    "C. Instantiate a KNN object with K=3, train it on the training set and test it on the testing set. Then, calculate the accuracy of your prediction as you learned in Lab3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b2130352-d263-4e91-b3f2-6b1a5db38f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with K=3: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the KNN classifier with K=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with K=3: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ced2e-253e-4eb1-a86d-054cb7802317",
   "metadata": {},
   "source": [
    "D. Repeat part (c) for K=1, K=3, K=5, K=11, K=15, K=27, K=43 (you can simply use a “for loop,” and save the final accuracy results in a list). Does the accuracy always get better by increasing the value K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "76cc587d-c98d-4c4d-b642-a70118694179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1, Accuracy=0.9166666666666666\n",
      "K=3, Accuracy=0.9333333333333333\n",
      "K=5, Accuracy=0.95\n",
      "K=11, Accuracy=0.9666666666666667\n",
      "K=15, Accuracy=0.95\n",
      "K=27, Accuracy=0.95\n",
      "K=43, Accuracy=0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Define a list of K values to evaluate\n",
    "k_values = [1, 3, 5, 11, 15, 27, 43]\n",
    "accuracies = []\n",
    "\n",
    "# Loop through each K, train the model, and calculate accuracy\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"K={k}, Accuracy={accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2011711-ce32-44a1-89dc-15e0cd41f519",
   "metadata": {},
   "source": [
    "#### Does the accuracy always get better by increasing the value K?\n",
    "\n",
    "No, increasing the value of K doesn't always improve accuracy.\n",
    "\n",
    "In the results:\n",
    "\n",
    "Accuracy improves when K goes from 1 to 11.\n",
    "But when K increases to 15, 27, and 43, accuracy either stays the same or drops.\n",
    "\n",
    "This happens because when K gets too large, the model starts considering too many neighbors, which can blur the boundaries between different classes, making predictions less accurate. The best K depends on the dataset, so it's important to test different values to find the one that works best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285af7dc-faff-443b-bc9f-32fce6b0f263",
   "metadata": {},
   "source": [
    "E. Now, suppose that we would like to make prediction based on only ONE single feature. To find the best single feature, we have to try every feature individually. In other word, we have to repeat part (c) with K=11, four times (each time using only one of the 4 features), and compute the accuracy each time. Then, check the accuracies. \n",
    "Which individual feature provide the best accuracy (the best feature)?  Which one is the second best feature? (Note: you have to train, test, and evaluate your model 4 times, each time on a dataset including only one of the features, and save the final accuracy results in a list).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9fef9b1f-105a-41a6-b5c5-8de4213ba402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1, sepal_length, Accuracy: 0.6166666666666667\n",
      "Feature 2, sepal_width, Accuracy: 0.5166666666666667\n",
      "Feature 3, petal_length, Accuracy: 0.95\n",
      "Feature 4, petal_width, Accuracy: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6166666666666667, 0.5166666666666667, 0.95, 0.95]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store accuracy for each individual feature\n",
    "individual_feature_accuracies = []\n",
    "\n",
    "# Loop through each feature (one at a time)\n",
    "for i in range(X.shape[1]):\n",
    "    X_single_feature = X.iloc[:, i].values.reshape(-1, 1)\n",
    "    X_train_single, X_test_single, y_train_single, y_test_single = train_test_split(X_single_feature, y, test_size=0.4, random_state=10)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=11)\n",
    "    knn.fit(X_train_single, y_train_single)\n",
    "    y_pred_single = knn.predict(X_test_single)\n",
    "\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_single, y_pred_single)\n",
    "    individual_feature_accuracies.append(accuracy)\n",
    "    print(f\"Feature {i+1}, {X.columns[i]}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Display the results for individual features\n",
    "individual_feature_accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca49cc0-e9a5-4af1-884a-10fae3b98231",
   "metadata": {},
   "source": [
    "#### Which individual feature provide the best accuracy (the best feature)?  Which one is the second best feature?\n",
    "\n",
    "The best accuracy is 0.95 of petal_length. \n",
    "The second best accuracy is 0.95  of petal_width.\n",
    "\n",
    "Then third best feature is sepal_length with accuracy of 0.6166666666666667."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e2086679-9f90-4312-9328-b009d2f70286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual feature is 'petal_length' with accuracy: 0.95\n",
      "Second best individual feature is 'petal_width' with accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Get the index of the best individual feature\n",
    "best_single_feature_idx = individual_feature_accuracies.index(max(individual_feature_accuracies))\n",
    "\n",
    "# Make a copy of the accuracies list and remove the best feature\n",
    "individual_feature_accuracies_copy = individual_feature_accuracies.copy()\n",
    "individual_feature_accuracies_copy[best_single_feature_idx] = -1  # Temporarily invalidate the best feature\n",
    "\n",
    "# Get the second best feature by finding the next maximum\n",
    "second_best_single_feature_idx = individual_feature_accuracies_copy.index(max(individual_feature_accuracies_copy))\n",
    "\n",
    "# Get the feature names\n",
    "best_feature_name = X.columns[best_single_feature_idx]\n",
    "second_best_feature_name = X.columns[second_best_single_feature_idx]\n",
    "\n",
    "# Print both the best and second best features\n",
    "print(f\"Best individual feature is '{best_feature_name}' with accuracy: {individual_feature_accuracies[best_single_feature_idx]}\")\n",
    "print(f\"Second best individual feature is '{second_best_feature_name}' with accuracy: {individual_feature_accuracies[second_best_single_feature_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b8fa91-7bab-42f2-bb0a-4010268a3ba5",
   "metadata": {},
   "source": [
    "D. Now, we want to repeat part (e) (with K=11), this time using two features. you have to train, test, and evaluate your model for 6 different cases: using (1st and 2nd features), (1st and 3rd features), (1st and 4th  features), (2nd  and 3rd  features), (2nd and 4th features), (3rd and 4th  features)!    \n",
    "Which “feature pair” provides the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "45da1a85-8483-4d62-ade5-2c3bdc497698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (0, 1): 'sepal_length' & 'sepal_width', Accuracy: 0.7166666666666667\n",
      "Features (0, 2): 'sepal_length' & 'petal_length', Accuracy: 0.9166666666666666\n",
      "Features (0, 3): 'sepal_length' & 'petal_width', Accuracy: 0.9166666666666666\n",
      "Features (1, 2): 'sepal_width' & 'petal_length', Accuracy: 0.95\n",
      "Features (1, 3): 'sepal_width' & 'petal_width', Accuracy: 0.9666666666666667\n",
      "Features (2, 3): 'petal_length' & 'petal_width', Accuracy: 0.95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7166666666666667,\n",
       " 0.9166666666666666,\n",
       " 0.9166666666666666,\n",
       " 0.95,\n",
       " 0.9666666666666667,\n",
       " 0.95]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List to store accuracy for each feature pair\n",
    "feature_pairs_accuracies = []\n",
    "\n",
    "# Define feature pairs (manual selection of 6 pairs)\n",
    "feature_pairs = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
    "\n",
    "# Loop through each pair of features\n",
    "for pair in feature_pairs:\n",
    "    feature_1_name = X.columns[pair[0]]\n",
    "    feature_2_name = X.columns[pair[1]]\n",
    "    \n",
    "    X_pair_features = X.iloc[:, [pair[0], pair[1]]]\n",
    "    X_train_pair, X_test_pair, y_train_pair, y_test_pair = train_test_split(X_pair_features, y, test_size=0.4, random_state=10)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=11)\n",
    "    knn.fit(X_train_pair, y_train_pair)\n",
    "    y_pred_pair = knn.predict(X_test_pair)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_pair, y_pred_pair)\n",
    "    feature_pairs_accuracies.append(accuracy)\n",
    "    \n",
    "    print(f\"Features {pair}: '{feature_1_name}' & '{feature_2_name}', Accuracy: {accuracy}\")\n",
    "\n",
    "# Display the results for feature pairs\n",
    "feature_pairs_accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "62d2e570-0480-4f33-9841-3a497b9a3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature pair is 'sepal_width' & 'petal_width' with accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Find the best feature pair\n",
    "best_feature_pair_idx = feature_pairs_accuracies.index(max(feature_pairs_accuracies))\n",
    "\n",
    "# Get the names of the best feature pair\n",
    "best_feature_pair_names = (X.columns[feature_pairs[best_feature_pair_idx][0]], X.columns[feature_pairs[best_feature_pair_idx][1]])\n",
    "\n",
    "# Print the results with feature names\n",
    "print(f\"Best feature pair is '{best_feature_pair_names[0]}' & '{best_feature_pair_names[1]}' with accuracy: {feature_pairs_accuracies[best_feature_pair_idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64736c71-333c-43f7-b7c5-0076c3c1e8eb",
   "metadata": {},
   "source": [
    "### Which “feature pair” provides the best accuracy?\n",
    "\n",
    "Best feature pair is 'sepal_width' & 'petal_width' with accuracy: 0.9666666666666667\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b56023f8-0344-4aa3-b85b-4d04becddc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual feature is 'petal_length' with accuracy: 0.95\n",
      "Second best individual feature is 'petal_width' with accuracy: 0.95\n",
      "Best feature pair is 'sepal_width' & 'petal_width' with accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Find the best and second best individual feature accuracies\n",
    "best_single_feature_idx = individual_feature_accuracies.index(max(individual_feature_accuracies))\n",
    "\n",
    "# Make a copy and remove the best feature to find the second-best\n",
    "individual_feature_accuracies_copy = individual_feature_accuracies.copy()\n",
    "individual_feature_accuracies_copy[best_single_feature_idx] = -1  # Temporarily invalidate the best feature\n",
    "second_best_single_feature_idx = individual_feature_accuracies_copy.index(max(individual_feature_accuracies_copy))\n",
    "\n",
    "# Find the best feature pair\n",
    "best_feature_pair_idx = feature_pairs_accuracies.index(max(feature_pairs_accuracies))\n",
    "\n",
    "# Get the names of the best and second-best individual features\n",
    "best_feature_name = X.columns[best_single_feature_idx]\n",
    "second_best_feature_name = X.columns[second_best_single_feature_idx]\n",
    "\n",
    "# Get the names of the best feature pair\n",
    "best_feature_pair_names = (X.columns[feature_pairs[best_feature_pair_idx][0]], X.columns[feature_pairs[best_feature_pair_idx][1]])\n",
    "\n",
    "# Print the results with feature names\n",
    "print(f\"Best individual feature is '{best_feature_name}' with accuracy: {individual_feature_accuracies[best_single_feature_idx]}\")\n",
    "print(f\"Second best individual feature is '{second_best_feature_name}' with accuracy: {individual_feature_accuracies[second_best_single_feature_idx]}\")\n",
    "print(f\"Best feature pair is '{best_feature_pair_names[0]}' & '{best_feature_pair_names[1]}' with accuracy: {feature_pairs_accuracies[best_feature_pair_idx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cb566-8066-40fd-a283-de4252d4a89e",
   "metadata": {},
   "source": [
    "#### Question: Does the “best feature pair” from part (f) contain of both “first best feature” and “second best feature” from part (e)? In other word, can we conclude that the “best two features” for classification are the first best feature along with the second best feature together? \n",
    "\n",
    "Justify you  answer. If yes, why?  If no, why not\n",
    "\n",
    "\n",
    "\n",
    "No, the \"best feature pair\" does not consist of both the \"best individual feature\" and the \"second best individual feature\" from part (e).\n",
    "\n",
    "In this case:\n",
    "\n",
    "The best individual features are 'petal_length' and 'petal_width' (both with 0.95 accuracy).\n",
    "However, the best feature pair is 'sepal_width' and 'petal_width', with a higher accuracy of 0.9667.\n",
    "This shows that even though 'petal_width' is part of both the best individual and pair classifications, 'petal_length' (the other best individual feature) does not appear in the best pair. Instead, 'sepal_width' appears with 'petal_width in the best feature pair.\n",
    "\n",
    "This indicates that the combination of 'sepal_width' and 'petal_width' works better together than 'petal_length' and 'petal_width' for classification. Therefore, we cannot conclude that the \"best two features\" for classification are simply the top two individual features used together. Sometimes, a different combination of features provides better classification performance.?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
